"""
å¯¦éš›æ¸¬è©¦ï¼šèª¿ç”¨çœŸå¯¦ AI ç”Ÿæˆå ±å‘Šï¼Œé©—è­‰æ‘˜è¦å’Œé‡é»åˆ†ææå–
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agents import ResearchAgent, AnalystAgent, ReportGeneratorAgent
from config import Config
import pandas as pd


def validate_config():
    """é©—è­‰é…ç½®"""
    if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY == "your-openai-api-key":
        print("âŒ è«‹å…ˆè¨­å®š OPENAI_API_KEY")
        return False
    print("âœ… é…ç½®é©—è­‰æˆåŠŸ")
    return True


def test_real_ai_workflow():
    """ä½¿ç”¨çœŸå¯¦ AI æ¸¬è©¦å®Œæ•´å·¥ä½œæµç¨‹"""
    if not validate_config():
        return
    
    print("=" * 80)
    print("çœŸå¯¦ AI æ¸¬è©¦ï¼šç”Ÿæˆå ±å‘Šä¸¦é©—è­‰æ‘˜è¦å’Œé‡é»åˆ†ææå–")
    print("=" * 80)
    print()
    
    # æ­¥é©Ÿ 1: æœå°‹ï¼ˆä½¿ç”¨è¼ƒå°‘çš„æ–‡ç« ä»¥ç¯€çœ tokensï¼‰
    print("ğŸ“ æ­¥é©Ÿ 1: åŸ·è¡Œæœå°‹")
    print("-" * 80)
    research_agent = ResearchAgent()
    search_results = research_agent.search(
        query="æ–°åŠ å¡é‡‘èç§‘æŠ€",
        time_instruction="æœ€è¿‘7å¤©å…§",
        num_instruction="2ç¯‡",  # åªè¦2ç¯‡ä»¥ç¯€çœæ™‚é–“
        language="English"
    )
    
    if search_results.get("status") == "error":
        print(f"âŒ æœå°‹å¤±æ•—: {search_results.get('error')}")
        return
    
    print(f"âœ… æœå°‹å®Œæˆ (å…§å®¹é•·åº¦: {len(search_results.get('content', ''))} å­—å…ƒ)")
    print()
    
    # æ­¥é©Ÿ 2: åˆ†æç”Ÿæˆå ±å‘Š
    print("ğŸ“ æ­¥é©Ÿ 2: AI åˆ†æä¸¦ç”Ÿæˆ Markdown å ±å‘Š")
    print("-" * 80)
    analyst_agent = AnalystAgent()
    markdown_report, structured_news = analyst_agent.analyze(search_results)
    
    print(f"âœ… å ±å‘Šç”Ÿæˆå®Œæˆ (Markdown é•·åº¦: {len(markdown_report)} å­—å…ƒ)")
    print(f"âœ… æå–åˆ° {len(structured_news)} å‰‡æ–°è")
    print()
    
    # æ­¥é©Ÿ 3: é¡¯ç¤º Markdown å ±å‘Šç‰‡æ®µ
    print("ğŸ“ æ­¥é©Ÿ 3: æª¢æŸ¥ Markdown å ±å‘Šæ ¼å¼")
    print("-" * 80)
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„æ ¼å¼æ¨™è¨˜
    has_title_marker = "###" in markdown_report
    has_source_marker = "**ä¾†æº**" in markdown_report or "**ä¾†æº**:" in markdown_report
    has_date_marker = "**æ—¥æœŸ**" in markdown_report or "**æ—¥æœŸ**:" in markdown_report
    has_summary_marker = "**æ‘˜è¦**" in markdown_report or "**æ‘˜è¦**:" in markdown_report
    has_analysis_marker = "**é‡é»åˆ†æ**" in markdown_report or "**é‡é»åˆ†æ**:" in markdown_report
    
    print(f"åŒ…å«æ¨™é¡Œæ¨™è¨˜ (###): {'âœ…' if has_title_marker else 'âŒ'}")
    print(f"åŒ…å«ä¾†æºæ¨™è¨˜: {'âœ…' if has_source_marker else 'âŒ'}")
    print(f"åŒ…å«æ—¥æœŸæ¨™è¨˜: {'âœ…' if has_date_marker else 'âŒ'}")
    print(f"åŒ…å«æ‘˜è¦æ¨™è¨˜: {'âœ…' if has_summary_marker else 'âŒ'}")
    print(f"åŒ…å«é‡é»åˆ†ææ¨™è¨˜: {'âœ…' if has_analysis_marker else 'âŒ'}")
    print()
    
    # é¡¯ç¤ºç¬¬ä¸€å‰‡æ–°èçš„å®Œæ•´å…§å®¹
    print("ğŸ“„ ç¬¬ä¸€å‰‡æ–°èçš„ Markdown åŸå§‹å…§å®¹:")
    print("=" * 80)
    import re
    news_sections = re.findall(r'(###\s+\d+\..*?)(?=###|\Z)', markdown_report, re.DOTALL)
    if news_sections:
        first_news = news_sections[0]
        print(first_news[:1500])  # é¡¯ç¤ºå‰1500å­—å…ƒ
        if len(first_news) > 1500:
            print("\n... (å…§å®¹è¢«æˆªæ–·)")
    print("=" * 80)
    print()
    
    # æ­¥é©Ÿ 4: æª¢æŸ¥æå–çš„çµæ§‹åŒ–æ•¸æ“š
    print("ğŸ“ æ­¥é©Ÿ 4: æª¢æŸ¥æå–çš„çµæ§‹åŒ–æ•¸æ“š")
    print("-" * 80)
    
    summary_count = 0
    analysis_count = 0
    
    for i, news in enumerate(structured_news, 1):
        print(f"\næ–°è {i}:")
        print(f"  ğŸ“° æ¨™é¡Œ: {news.get('æ–°èæ¨™é¡Œï¼ˆä¸­æ–‡ï¼‰', 'N/A')[:60]}...")
        print(f"  ğŸŒ åœ‹å®¶: {news.get('ä¾†æºåœ‹å®¶', 'N/A')}")
        print(f"  ğŸ“… æ—¥æœŸ: {news.get('ç™¼å¸ƒæ—¥æœŸ', 'N/A')}")
        print(f"  ğŸ”— é€£çµ: {news.get('ä¾†æºç¶²ç«™é€£çµ', 'N/A')[:60]}...")
        
        summary = news.get('æ‘˜è¦', '')
        analysis = news.get('é‡é»åˆ†æ', '')
        
        if summary and summary.strip():
            summary_count += 1
            print(f"  ğŸ“ æ‘˜è¦: {summary[:100]}..." if len(summary) > 100 else f"  ğŸ“ æ‘˜è¦: {summary}")
            print(f"      âœ… æ‘˜è¦æœ‰å…§å®¹ ({len(summary)} å­—å…ƒ)")
        else:
            print(f"      âŒ æ‘˜è¦ç‚ºç©º")
        
        if analysis and analysis.strip():
            analysis_count += 1
            print(f"  ğŸ¯ é‡é»åˆ†æ: {analysis[:100]}..." if len(analysis) > 100 else f"  ğŸ¯ é‡é»åˆ†æ: {analysis}")
            print(f"      âœ… é‡é»åˆ†ææœ‰å…§å®¹ ({len(analysis)} å­—å…ƒ)")
        else:
            print(f"      âŒ é‡é»åˆ†æç‚ºç©º")
    
    print()
    print(f"ğŸ“Š çµ±è¨ˆ: æ‘˜è¦ {summary_count}/{len(structured_news)}, é‡é»åˆ†æ {analysis_count}/{len(structured_news)}")
    print()
    
    # æ­¥é©Ÿ 5: ç”Ÿæˆ Excel
    print("ğŸ“ æ­¥é©Ÿ 5: ç”Ÿæˆ Excel ä¸¦é©—è­‰")
    print("-" * 80)
    
    report_agent = ReportGeneratorAgent()
    excel_path = report_agent.generate_excel(structured_news, "çœŸå¯¦æ¸¬è©¦_å«æ‘˜è¦åˆ†æ.xlsx")
    
    print(f"âœ… Excel å·²ç”Ÿæˆ: {excel_path}")
    print(f"   æª”æ¡ˆå¤§å°: {excel_path.stat().st_size / 1024:.2f} KB")
    print()
    
    # æ­¥é©Ÿ 6: è®€å–ä¸¦é©—è­‰ Excel
    print("ğŸ“ æ­¥é©Ÿ 6: è®€å– Excel é©—è­‰å…§å®¹")
    print("-" * 80)
    
    df = pd.read_excel(excel_path)
    
    print(f"Excel æ¬„ä½: {list(df.columns)}")
    print(f"è³‡æ–™ç­†æ•¸: {len(df)}")
    print()
    
    if 'æ‘˜è¦' in df.columns and 'é‡é»åˆ†æ' in df.columns:
        excel_summary_count = df['æ‘˜è¦'].notna().sum()
        excel_analysis_count = df['é‡é»åˆ†æ'].notna().sum()
        
        print(f"Excel ä¸­æœ‰å…§å®¹çš„æ‘˜è¦: {excel_summary_count}/{len(df)}")
        print(f"Excel ä¸­æœ‰å…§å®¹çš„é‡é»åˆ†æ: {excel_analysis_count}/{len(df)}")
        print()
        
        # é¡¯ç¤º Excel ä¸­çš„è³‡æ–™
        print("Excel è³‡æ–™é è¦½:")
        print("=" * 80)
        pd.set_option('display.max_columns', None)
        pd.set_option('display.max_colwidth', 60)
        print(df.to_string(index=False))
        print("=" * 80)
    else:
        print("âŒ Excel ç¼ºå°‘æ‘˜è¦æˆ–é‡é»åˆ†ææ¬„ä½ï¼")
    
    print()
    
    # æœ€çµ‚çµè«–
    print("=" * 80)
    print("ğŸ¯ æ¸¬è©¦çµè«–")
    print("=" * 80)
    
    if summary_count == len(structured_news) and analysis_count == len(structured_news):
        print("âœ… å®Œå…¨æˆåŠŸï¼æ‰€æœ‰æ–°èéƒ½æˆåŠŸæå–æ‘˜è¦å’Œé‡é»åˆ†æ")
    elif summary_count > 0 or analysis_count > 0:
        print(f"âš ï¸ éƒ¨åˆ†æˆåŠŸï¼š{summary_count}/{len(structured_news)} æ‘˜è¦, {analysis_count}/{len(structured_news)} é‡é»åˆ†æ")
        print("\nå¯èƒ½çš„åŸå› ï¼š")
        print("1. AI æ²’æœ‰åš´æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼ç”Ÿæˆå…§å®¹")
        print("2. éƒ¨åˆ†æ–°èç¼ºå°‘æ‘˜è¦æˆ–é‡é»åˆ†ææ¬„ä½")
        print("3. æ­£å‰‡è¡¨é”å¼éœ€è¦é€²ä¸€æ­¥èª¿æ•´")
    else:
        print("âŒ å¤±æ•—ï¼šæ‰€æœ‰æ‘˜è¦å’Œé‡é»åˆ†æéƒ½æ˜¯ç©ºå€¼")
        print("\néœ€è¦æª¢æŸ¥ï¼š")
        print("1. Markdown å ±å‘Šçš„å¯¦éš›æ ¼å¼")
        print("2. æ­£å‰‡è¡¨é”å¼æ˜¯å¦èƒ½åŒ¹é…å¯¦éš›æ ¼å¼")
        print("3. AI æŒ‡ä»¤æ˜¯å¦æ˜ç¢º")
    
    print()
    print(f"ğŸ“ è©³ç´°è³‡æ–™è«‹æŸ¥çœ‹: {excel_path}")
    print("=" * 80)


if __name__ == "__main__":
    test_real_ai_workflow()
