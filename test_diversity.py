"""
æ¸¬è©¦æ–°èä¾†æºå¤šæ¨£æ€§
"""
from agents.research_agent import ResearchAgent
from urllib.parse import urlparse
import json

def extract_domain(url):
    """å¾ URL ä¸­æå–åŸŸå"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc or parsed.path
        # ç§»é™¤ www.
        if domain.startswith('www.'):
            domain = domain[4:]
        return domain
    except:
        return None

def test_diversity():
    """æ¸¬è©¦æ–°èä¾†æºçš„å¤šæ¨£æ€§"""
    print("=" * 70)
    print("ğŸ§ª æ¸¬è©¦æ–°èä¾†æºå¤šæ¨£æ€§")
    print("=" * 70)
    
    # åˆå§‹åŒ– Research Agent
    agent = ResearchAgent()
    
    # æ¸¬è©¦æŸ¥è©¢ï¼ˆæ¨¡æ“¬ç”¨æˆ¶è¼¸å…¥ï¼‰
    test_cases = [
        {
            "query": "æ³°åœ‹æ•¸ä½æ”¯ä»˜",
            "time": "æœ€è¿‘ 30 å¤©å…§",
            "count": "5-8ç¯‡",
            "language": "English"
        },
        {
            "query": "è¶Šå—é‡‘èç§‘æŠ€",
            "time": "æœ€è¿‘ 30 å¤©å…§",
            "count": "5-8ç¯‡",
            "language": "English"
        },
        {
            "query": "æ±å—äºåŠ å¯†è²¨å¹£ç›£ç®¡",
            "time": "æœ€è¿‘ 30 å¤©å…§",
            "count": "5-8ç¯‡",
            "language": "English"
        }
    ]
    
    allowed_domains = [src['domain'] for src in agent.TRUSTED_NEWS_SOURCES]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'=' * 70}")
        print(f"ğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ {i}: {test_case['query']}")
        print(f"   æ™‚é–“ç¯„åœ: {test_case['time']}")
        print(f"   æ•¸é‡è¦æ±‚: {test_case['count']}")
        print(f"   èªè¨€: {test_case['language']}")
        print("=" * 70)
        
        # åŸ·è¡Œæœå°‹
        result = agent.search(
            query=test_case['query'],
            time_instruction=test_case['time'],
            num_instruction=test_case['count'],
            language=test_case['language']
        )
        
        print(f"\nâœ… Research Agent æœå°‹å®Œæˆ\n")
        
        # è§£æçµæœ
        try:
            if isinstance(result, dict) and 'content' in result:
                content = result['content']
            else:
                content = str(result)
            
            # å˜—è©¦æå– JSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                data = json.loads(json_match.group())
            else:
                print("âš ï¸  ç„¡æ³•è§£æ JSON çµæœ")
                print(f"åŸå§‹çµæœ: {content[:500]}")
                continue
            
            articles = data.get('articles', [])
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(articles)} ç¯‡æ–°è\n")
            
            # çµ±è¨ˆä¾†æºåˆ†å¸ƒ
            source_count = {}
            valid_count = 0
            invalid_count = 0
            
            for idx, article in enumerate(articles, 1):
                title = article.get('title', 'No title')[:60]
                url = article.get('url', '')
                source = article.get('source', 'Unknown')
                
                domain = extract_domain(url)
                is_valid = domain in allowed_domains
                
                if is_valid:
                    valid_count += 1
                    source_count[domain] = source_count.get(domain, 0) + 1
                    status = "âœ…"
                else:
                    invalid_count += 1
                    status = "âŒ"
                
                print(f"{idx}. {status} {title}...")
                print(f"   ä¾†æº: {source}")
                print(f"   åŸŸå: {domain}")
                print()
            
            # é¡¯ç¤ºçµ±è¨ˆ
            print("=" * 70)
            print("ğŸ“ˆ ä¾†æºå¤šæ¨£æ€§åˆ†æ")
            print("=" * 70)
            print(f"âœ… ç¬¦åˆæŒ‡å®šä¾†æº: {valid_count} ç¯‡ ({valid_count/len(articles)*100:.1f}%)")
            print(f"âŒ éæŒ‡å®šä¾†æº: {invalid_count} ç¯‡ ({invalid_count/len(articles)*100:.1f}%)")
            
            if source_count:
                print(f"\nğŸ“Š ä¾†æºåˆ†å¸ƒ:")
                sorted_sources = sorted(source_count.items(), key=lambda x: x[1], reverse=True)
                for domain, count in sorted_sources:
                    percentage = count / len(articles) * 100
                    bar = "â–ˆ" * int(percentage / 5)
                    print(f"   {domain:30s}: {count:2d} ç¯‡ ({percentage:5.1f}%) {bar}")
                
                # è¨ˆç®—å¤šæ¨£æ€§æŒ‡æ¨™
                unique_sources = len(source_count)
                diversity_score = unique_sources / len(agent.TRUSTED_NEWS_SOURCES) * 100
                print(f"\nğŸ¯ å¤šæ¨£æ€§æŒ‡æ¨™:")
                print(f"   ä½¿ç”¨äº† {unique_sources} å€‹ä¸åŒä¾†æº (å…±18å€‹å¯ç”¨ä¾†æº)")
                print(f"   å¤šæ¨£æ€§å¾—åˆ†: {diversity_score:.1f}%")
                
                if diversity_score < 30:
                    print(f"   âš ï¸  ä¾†æºå¤šæ¨£æ€§è¼ƒä½ï¼Œå»ºè­°æ”¹å–„")
                elif diversity_score < 50:
                    print(f"   â„¹ï¸  ä¾†æºå¤šæ¨£æ€§ä¸­ç­‰")
                else:
                    print(f"   âœ… ä¾†æºå¤šæ¨£æ€§è‰¯å¥½")
            
        except Exception as e:
            print(f"âŒ è§£æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"åŸå§‹çµæœ: {str(result)[:500]}")

if __name__ == "__main__":
    test_diversity()
